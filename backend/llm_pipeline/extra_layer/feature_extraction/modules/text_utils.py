def tokenize(text: str) -> list:
    """
    Splits the text into tokens (words).
    """
    return text.split()
